<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<?asciidoc-toc?>
<?asciidoc-numbered?>

<book lang="en">
<bookinfo>
    <title>SUSE&#174; CaaS Platform Reference Implementation on Dell EMC&#174; Hardware</title>
    <author>
        <firstname>Bryan Gartner, SUSE &lt; bryan.gartner@suse.com&gt;</firstname>
    </author>
    <authorinitials>B</authorinitials>
</bookinfo>
<chapter id="_introduction">
<title>Introduction</title>
<simpara>This white paper is intended to help an organization create and deploy an on-premise container-as-a-service platform instance to deploy, orchestrate and manage containerized workloads.</simpara>
<section id="_description">
<title>Description</title>
<simpara>As with any software-defined infrastructure, all the classic IT disciplines around networking, computing and storage are involved and need to be effectively planned and integrated.
This document provides a reference implementation from proof-of-concept to production ready deployments with design considerations, implementation suggestions, and best practices.
The combination of Dell EMC&#174; Network S-Series Network Switches and PowerEdge R640 Rack Servers computing hardware plus the SUSE&#174; CaaS Platform software solution yields a fully functional, container-as-a-service infrastructure.</simpara>
<itemizedlist>
<listitem>
<simpara>
To ease the adoption curve and provide multiple proof points, the infrastructure can be quickly deployed as a proof-of-concept utilizing only virtual machines for evaluation of the solution.
</simpara>
</listitem>
<listitem>
<simpara>
To address increases in workload capacity, physical systems with more resources can be iteratively added to the existing cluster and even replace some of the initial roles on virtual machines.
</simpara>
</listitem>
<listitem>
<simpara>
To accomodate increased adoption of the solution, cluster-wide functions can be migrated to a full, production instance to provide all the required functionality and services for administrators, developers and users to operate at scale.
</simpara>
</listitem>
</itemizedlist>
<simpara>Each of these modes are detailed, citing considerations and requirements necessary to move seamlessly through the modes.
For the final production mode, one has an operationally complete solution that can be monitored and maintained over time.
In addition, core functions are deploying in a highly available fashion to help prevent downtime and multiple user interfaces are made available.
To compliment the solution, an integration with a Ceph-based storage backend is provided the persistent data storage needed to allow stateful components for the containerized workloads.</simpara>
<simpara>The deployment process for each of these modes was implemented, tested and validated in the Dell EMC Partner lab.</simpara>
</section>
<section id="_target_audience">
<title>Target Audience</title>
<simpara>The target audience for this document is IT professionals responsible for setting up, configuring, administering and operating a container-ready infrastructure.
It is suggested that this document is reviewed in its entirety, along with the referenced supplemental documentation before attempting the deployment.</simpara>
</section>
</chapter>
<chapter id="_business_problem_and_business_value">
<title>Business problem and business value</title>
<simpara>In the rapidly evolving era of DevOps, containerized workloads are becoming increasingly popular.
Both developers and users need an API-centric platform to continuously integrate with, rapidly deploy to, and utilize applications that can scale as required.
Operational teams need the ability to set up and manage such a software-defined infrastructure quickly and easily, yet with the ability to maintain it over time.
By providing an easy to deploy and scale container-as-a-service platform, organizations can begin migrating their business applications from legacy monolithic applications to micro-service cloud-native solutions in a low-risk fashion.</simpara>
<section id="_business_problem">
<title>Business problem</title>
<simpara>Providing an environment to support containerized workload applications requires a robust, software-defined infrastructure including networking, computing platforms and persistent storage.
Since it is a combination of all the classic disciplines, IT administrators appreciate a solution that is synergistically more than a sum of the indvidual components and is easy to configure, maintain, secure and adjust over time to react to changing needs.</simpara>
</section>
<section id="_business_value">
<title>Business value</title>
<simpara>Each of these three components, networking, compute and software provide individual value-add to address the overall requirements of the solution :</simpara>
<variablelist>
<varlistentry>
<term>
Dell EMC Network Switches
</term>
<listitem>
<simpara>
Dell EMC data center switching solutions are cost-effective and easy to deploy at any scale, from 1G to multi-rate 100G for optimum connectivity both within the rack or blade chassis and across the data center.
The switching solutions also feature a choice of innovative Dell EMC and third-party software options to address virtually any enterprise or service provider use-case or environment.
For the physical switching layer, Dell EMC S-Series top-of-rack (ToR) open networking switches like the 10GbE S4048-ON are cost-effective and easy to deploy at any scale for optimum connectivity both within the rack or chassis and across the data center fabric.
The switches also feature a choice of innovative Dell EMC or third-party software options.
To complete the networking solution, a Dell EMC Networking 1GbE S3048-ON open networking switch is used to handle management functions.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Dell EMC PowerEdge Servers
</term>
<listitem>
<simpara>
The Dell EMC PowerEdge R640 and R740xd deliver a perfect balance between storage scalability and performance.
Both two-socket platforms are ideal for software defined storage (like ScaleIO, VSAN or the PowerEdge XC), service providers or Big Data servers.
The platform versatility is highlighted with the ability to mix any drive type to create the optimum configuration of NVMe, SSD and HDD for either performance, capacity or both.
The R740xd drives fast response times for business-critical workloads with up to 24 NVMe drives for storage intensive roles with optimum performance.
Both platforms support the Dell EMC OpenManage™ portfolio, delivering intelligent, automated management of routine tasks.
Combined with unique agent-free management capabilities, the R640/R740xd are simply managed, freeing up time for high profile projects.
The R640/R740xd leverage new security features built-into every new PowerEdge server strengthening protection so you can reliably and securely deliver accurate data to your customers no matter where they are.
By considering each aspect of system security, from design to retirement, Dell EMC ensures trust and delivers a worry-free, secure infrastructure without compromise.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Software Defined Infrastructure
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
SUSE CaaS Platform is an enterprise class container management solution that enables IT and DevOps professionals to more easily deploy, manage, and scale container-based applications and services.
It includes Kubernetes to automate lifecycle management of modern applications, and surrounding technologies that enrich Kubernetes and make the platform itself easy to operate.
As a result, enterprises that use SUSE CaaS Platform can reduce application delivery cycle times and improve business agility.
</simpara>
</listitem>
<listitem>
<simpara>
SUSE is focused on delivering an exceptional operator experience with SUSE CaaS Platform.
With deep competencies in infrastructure, systems, process integration, platform security, lifecycle management and enterprise-grade support, SUSE aims to ensure IT operations teams can deliver the power of Kubernetes to their users quickly, securely and efficiently.
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<figure id="img-CaaSP"><title>SUSE CaaS Platform</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="CaaSP.png"/>
  </imageobject>
  <textobject><phrase>SUSE CaaS Platform</phrase></textobject>
</mediaobject>
</figure>
</section>
</chapter>
<chapter id="_requirements">
<title>Requirements</title>
<simpara>Container-as-a-Service Platforms require reliability, manageability and serviceability.
These requirements span the multiple layers of such a solution, from the container host operating system, the container runtime engine and the container orchestration system.
Such demands are inherited from previous generations of IT infrastructure expectations and carry forward, even though the containerized workloads themselves have vastly different approaches through agility and resiliency.</simpara>
<variablelist>
<varlistentry>
<term>
With SUSE CaaS Platform you can
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Achieve faster time to value with an enterprise-ready container management platform, built from industry-leading technologies, and delivered as a complete package, with everything you need to quickly offer container services.
</simpara>
</listitem>
<listitem>
<simpara>
Simplify management and control of your container platform with efficient installation, easy scaling, and update automation.
</simpara>
</listitem>
<listitem>
<simpara>
Maximize return on your investment, with a flexible container services solution for today and tomorrow
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<figure id="img-CaaSPOrbit"><title>SUSE CaaS Platform Features</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="CaaSPOrbit.png"/>
  </imageobject>
  <textobject><phrase>SUSE CaaS Platform Orbits</phrase></textobject>
</mediaobject>
</figure>
</chapter>
<chapter id="_architectural_overview">
<title>Architectural overview</title>
<simpara>As noted in <xref linkend="_description"/> section, this document provides the deployment steps to create a container-as-a-service instance, starting off in a proof-of-concept mode and transitioning through to a full, production mode setup.</simpara>
<simpara>Underlying each of these deployment modes, however is a core set of functionality and architectural components:</simpara>
<itemizedlist>
<listitem>
<simpara>
Container-as-a-Service Platform
</simpara>
<variablelist>
<varlistentry>
<term>
Host Operating System
</term>
<listitem>
<simpara>
Typically a small footprint operating system installation, having just enough functionality to support the container runtime engine, leaving as many CPU, memory and I/O resources available for the containerized workloads.
</simpara>
<itemizedlist>
<listitem>
<simpara>
SUSE currently delivers this as MicroOS, a read-mostly, minimal operating system based upon SUSE Linux Enterprise Server.  This is complemented by a distributed key-value store provided by etcd to retain persistent configuration data. In addition, MicroOS provides a snapshot-driven, transactional-update methodology to perform atomic upgrades.
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Container Runtime Engine(s)
</term>
<listitem>
<simpara>
Comprised of both a format for and service to run containerized applications on top of the host operating system.
</simpara>
<itemizedlist>
<listitem>
<simpara>
SUSE provides support for Docker&#174; Community Edition Engine, the current, defacto standard open source format for application containers.
</simpara>
</listitem>
<listitem>
<simpara>
SUSE also offers a technical preview of CRI-O, an implementation of Container Runtime Interface (CRI), designed specifically for Kubernetes as a lightweight alternative, using Open Container Initiative (OCI) images.
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Container Networking
</term>
<listitem>
<simpara>
An intra-cluster service and overlay network used for container and orchestration communication.
</simpara>
<itemizedlist>
<listitem>
<simpara>
SUSE currently utilizes the Container Network Interface (CNI) with the Flannel plugin and a configuration management web-interface to setup and deploy these networks. More details follow in the <xref linkend="_networking_architecture"/> section.
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Container Orchestration
</term>
<listitem>
<simpara>
A service to manage deployments of containerized workload, known as Kubernetes, the current, defacto standard open source implementation for container orchestration.
</simpara>
<itemizedlist>
<listitem>
<simpara>
SUSE currently delivers and supports a Cloud-Native Computing Foundation (CNCF) certified Kubernetes distribution. Included with this is a role-based access control technology to, as desired, limit access to resources, functions and services.
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
</listitem>
<listitem>
<simpara>
Miscellaneous Infrastructure Components and Services
</simpara>
<variablelist>
<varlistentry>
<term>
Core Infrastructure Components / Services
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Domain Name Service (DNS) - an external network-accessible service to map IP Addresses to hostnames
</simpara>
</listitem>
<listitem>
<simpara>
Network Time Protocol (NTP) - an external network-accessible service to obtain and synchronize system times to aid in timestamp consistency
</simpara>
</listitem>
<listitem>
<simpara>
Software Update Service - access to a network-based repository for software update packages. This can be accessed directly from each node via registration to the <ulink url="http://scc.suse.com">SUSE Customer Center</ulink> or from local servers running a SUSE <ulink url="https://www.suse.com/documentation/sles-12/singlehtml/book_smt/book_smt.htm">Subscription Management Tool</ulink> (SMT) instance. As each node is deployed, it can be pointed to the respective update service and update notification and applicate will be managed by the configuration management web interface.
</simpara>
</listitem>
<listitem>
<simpara>
Client System - one or more existing system, with your choice of operating system, used to access the cluster and various services provided from a command line, via <literal>kubectl</literal> and <literal>helm</literal>, and web browser.
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
</listitem>
</itemizedlist>
<section id="_solution_architecture">
<title>Solution architecture</title>
<simpara>In addition to these high-level architectural components, SUSE CaaS Platform provides and relies upon the following types of nodes / roles:</simpara>
<note><simpara>Refer to the "Architectural Overview" section of <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Deployment Guide</ulink> for more details.</simpara></note>
<variablelist>
<varlistentry>
<term>
Admininstration Node
</term>
<listitem>
<simpara>
Provides a cluster infrastructure management system, with each service run as containers on this host and providing configuration management plus a web-based dashboard to manage other node types within the cluster
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Master Node(s)
</term>
<listitem>
<simpara>
Oversees Kubernetes container workload orchestration services across the cluster, and manages the Kubernetes Worker Nodes
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Worker Node(s)
</term>
<listitem>
<simpara>
Where the user-defined containerized workloads and services run in Kubernetes pods
</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="_networking_architecture">
<title>Networking architecture</title>
<simpara>The following networking requirements must be in place for a successful deployment:</simpara>
<note><simpara>Refer to the "Networking Requirements" section of <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Deployment Guide</ulink> for more details and port specifics.</simpara></note>
<variablelist>
<varlistentry>
<term>
Cluster network
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Choose a subnet range that will span the total number of cluster nodes. This range can also be segmented or secured for access to specific node roles as desired.
</simpara>
</listitem>
<listitem>
<simpara>
All of the cluster node types must be able to communicate on the same network, with this primary network interface card. A client system with similar network access is also required for command-line and web browser interaction with the cluster, especially during setup.
</simpara>
</listitem>
<listitem>
<simpara>
Higher speed network interface cards (minimum of 10GigE and above) and switching are preferred, since the number of containerized workloads can be high and they share this infrastructure capacity, both from an external and intra-cluster perspective.
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Internal networks
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Known as the Overlay and Service networks, these are used by Kubernetes and the underlying Flannel network plug-in to manage the internal cluster and container connections. These are implemented with bridges to the main cluster network.
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<important><simpara>These internal network ranges should be planned prior to deployment, are usually non-routable network ranges and cannot be changed without redploying the entire cluster.</simpara></important>
<variablelist>
<varlistentry>
<term>
Network services
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Ensure that an external DNS service is accessible, and configured for each cluster node to resolve all node names, uniquely. At least the Administration Node and Kubernetes API Master must resolve in a Fully Qualified Domain Name (FQDN) fashion for external clients to connect to these respective cluster nodes.
</simpara>
</listitem>
<listitem>
<simpara>
Ensure the Administration Node is pointed to a reliable, external NTP service and the remaining nodes will, by default, point to the Administration Node.
</simpara>
</listitem>
<listitem>
<simpara>
Ensure all cluster nodes have access to a software update repository to facilitate upgrades over time.
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
</section>
</chapter>
<chapter id="_deployment">
<title>Deployment</title>
<simpara>This section is meant as a companion guide to the official network, system and software product deployment documentation, citing specific settings as needed for this reference implementation. Default settings are assumed to be in use unless otherwise cited to accomplish the respective best practices and design decisions herein.</simpara>
<section id="_network_deployment_configuration">
<title>Network Deployment configuration</title>
<simpara>The following considerations for the network switching configuration should be attended to:</simpara>
<itemizedlist>
<listitem>
<simpara>
Configure 802.3ad for system port bonding, if used, and for VLT between the top-of-rack switches, if possible to get the maximum performance of bonded network interfaces
</simpara>
</listitem>
<listitem>
<simpara>
Connect the Dell EMC PowerEdge server’s iDRAC to a management network, which can be co-reside with the cluster network or entirely distinct, depending upon your local administration policies
</simpara>
</listitem>
</itemizedlist>
<important><simpara>Ensure that all similar switching devices are consistent and up-to-date with regard to firmware versions to reduce potential troubleshooting issues later.</simpara></important>
<tip><simpara>Meticulous care of the network wiring from the various resource nodes and switches makes troubleshooting much easier. Where possible, also label connections and stick to consistent patterns of port/placement of connections.</simpara></tip>
<figure id="img-OverviewNW"><title>Logical View of Deployment Network</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="OverviewNW.png"/>
  </imageobject>
  <textobject><phrase>Network</phrase></textobject>
</mediaobject>
</figure>
<simpara>The following considerations for various network service configurations should be attended to:</simpara>
<itemizedlist>
<listitem>
<simpara>
Setup external DNS A records for all nodes. Decide on subnet ranges and configure the switch ports accordingly to match those nodes in use.
</simpara>
</listitem>
<listitem>
<simpara>
Ensure that you have access to a valid, reliable external NTP service, as this is a critical requirement for all nodes.
</simpara>
</listitem>
<listitem>
<simpara>
Ensure access to software security updates and fixes by registering nodes to the <ulink url="http://scc.suse.com">SUSE Customer Center</ulink>, or creating a local <ulink url="https://www.suse.com/documentation/sles-12/singlehtml/book_smt/book_smt.html">Subscription Management Tool</ulink> service.
</simpara>
</listitem>
</itemizedlist>
<simpara>For this reference implementation, the following IP / Hostname settings were utilized and configured in the accessible external DNS service:</simpara>
<itemizedlist>
<listitem>
<simpara>
Network IP addressing and IP ranges need proper planning to address current as well as future growth.
</simpara>
</listitem>
</itemizedlist>
<table
frame="all"
rowsep="1" colsep="1"
>
<title>Network Address Configuration</title>
<tgroup cols="5">
<colspec colname="col_1" colwidth="20*"/>
<colspec colname="col_2" colwidth="20*"/>
<colspec colname="col_3" colwidth="20*"/>
<colspec colname="col_4" colwidth="20*"/>
<colspec colname="col_5" colwidth="20*"/>
<thead>
<row>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Function</emphasis></emphasis> </entry>
<entry align="left" valign="top"> <emphasis role="strong"><emphasis>Role</emphasis></emphasis> </entry>
<entry align="left" valign="top"> <emphasis role="strong"><emphasis>Mode</emphasis></emphasis> </entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Hostname</emphasis></emphasis> </entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>IP Address</emphasis></emphasis></entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>core</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">Solution Admin Host (SAH)</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>PoC, V2P, Production</simpara></entry>
<entry align="left" valign="top"><simpara>sah.suse-dell.net</simpara></entry>
<entry align="left" valign="top"><simpara>10.204.92.86</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">K8s Master LB</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>PoC, V2P, Production</simpara></entry>
<entry align="left" valign="top"><simpara>mstr-lb.suse-dell.net</simpara></entry>
<entry align="left" valign="top"><simpara>10.204.92.245</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>cluster</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">CaaSP-Admin (VM)</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>PoC, V2P, Production</simpara></entry>
<entry align="left" valign="top"><simpara>caasp-admin.suse-dell.net</simpara></entry>
<entry align="left" valign="top"><simpara>10.204.92.244</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">Overlay Network</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>PoC, V2P, Production</simpara></entry>
<entry align="left" valign="top"><simpara>n/a</simpara></entry>
<entry align="left" valign="top"><simpara>172.16.0.0/13</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">Service Network</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>PoC, V2P, Production</simpara></entry>
<entry align="left" valign="top"><simpara>n/a</simpara></entry>
<entry align="left" valign="top"><simpara>172.24.0.0/16</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">K8s-Master0 (VM)</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>PoC, V2P</simpara></entry>
<entry align="left" valign="top"><simpara>k8s-master-0.suse-dell.net</simpara></entry>
<entry align="left" valign="top"><simpara>10.204.92.246</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">K8s-Worker0 (VM)</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>PoC</simpara></entry>
<entry align="left" valign="top"><simpara>k8s-worker-0.suse-dell.net</simpara></entry>
<entry align="left" valign="top"><simpara>10.204.92.58</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">K8s-Worker1 (VM)</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>PoC</simpara></entry>
<entry align="left" valign="top"><simpara>k8s-worker-1.suse-dell.net</simpara></entry>
<entry align="left" valign="top"><simpara>10.204.92.59</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">CaaSP-Worker2</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>V2P, Production</simpara></entry>
<entry align="left" valign="top"><simpara>wrkr-2.suse-dell.net</simpara></entry>
<entry align="left" valign="top"><simpara>10.204.92.28</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">CaaSP-Worker3</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>V2P, Production</simpara></entry>
<entry align="left" valign="top"><simpara>wrkr-3.suse-dell.net</simpara></entry>
<entry align="left" valign="top"><simpara>10.204.92.29</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">CaaSP-MasterA</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Production</simpara></entry>
<entry align="left" valign="top"><simpara>mstr-a.suse-dell.net</simpara></entry>
<entry align="left" valign="top"><simpara>10.204.92.50</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">CaaSP-MasterB</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Production</simpara></entry>
<entry align="left" valign="top"><simpara>mstr-b.suse-dell.net</simpara></entry>
<entry align="left" valign="top"><simpara>10.204.92.60</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">CaaSP-MasterC</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Production</simpara></entry>
<entry align="left" valign="top"><simpara>mstr-c.suse-dell.net</simpara></entry>
<entry align="left" valign="top"><simpara>10.204.92.70</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section id="_hw_deployment_configuration">
<title>HW Deployment configuration</title>
<simpara>The following considerations for the system platforms should be attended to:</simpara>
<note><simpara>Any <ulink url="https://www.suse.com/yessearch/">SUSE YES</ulink> certified Dell EMC platform, like the PowerEdge R640, can be used for the physical nodes of this deployment, as long as the certification refers to the version of the underlying SUSE operating system used by SUSE CaaS Platform.</simpara></note>
<itemizedlist>
<listitem>
<simpara>
Reset the BIOS setup configuration to the default setting to have a known baseline configuration to provide consistency.
</simpara>
</listitem>
<listitem>
<simpara>
If possible, setup RAID1 mirroring on the storage controller across a pair of drives for the operating system installation
</simpara>
</listitem>
</itemizedlist>
<important><simpara>Ensure that all similar system devices are consistent and up-to-date with regard to BIOS/uEFI/device firmware versions to reduce potential troubleshooting issues later</simpara></important>
</section>
<section id="_sw_deployment_configuration">
<title>SW Deployment configuration</title>
<itemizedlist>
<listitem>
<simpara>
From the <ulink url="https://download.suse.com">SUSE Downloads</ulink> site, obtain the SUSE CaaS Platform install media (DVD1) and utilize either trial or purchased subscriptions for the cluster nodes to ensure access to support and software updates.
</simpara>
</listitem>
<listitem>
<simpara>
From the same download site, for the Solution Admin Host, obtain the SUSE Linux Enterprise Server 12-SP3 (DVD1) operating system install media.
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_solution_admin_host">
<title>Solution Admin Host</title>
<itemizedlist>
<listitem>
<simpara>
Solution Admin Host (SAH)
Because of the need for various administrative-like services, a convenient approach is to create a Solution Admin Host (SAH) that consolidates these services.
Given a finite number of physical systems, this consolidation helps to preserve other system nodes for more resource-intensive use by deploying virtual machine guests for various administrative functions.
</simpara>
</listitem>
</itemizedlist>
<tip><simpara>A simple hypervisor host, using KVM, provides the platform for the SAH and enables further grouping of administrative functions here as virtual machines.</simpara></tip>
<simpara>Using an available system, perform a bare-metal installation of the SUSE Linux Enterprise Server 12-SP3 operating system with either physical media or virtual media through iDRAC</simpara>
<note><simpara>The default partitioning scheme can be used, but remember to store any virtual machine images into the larger home directory partition or create a distinct partition for <emphasis>/var/lib/libvirt</emphasis>. For more details, refer to <ulink url="https://www.suse.com/documentation/sles-12">SUSE Virtualization Guide</ulink></simpara></note>
<itemizedlist>
<listitem>
<simpara>
A minimal system can be installed, with at least the following patterns include:
</simpara>
<itemizedlist>
<listitem>
<simpara>
base, minimal, kvm_server, kvm_tools
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
Register the system to the SUSE Customer Center (SCC) or a local SMT server during or after the installation to ensure all the latest software updates are present.
</simpara>
</listitem>
<listitem>
<simpara>
After the installation completes, use YaST to:
</simpara>
<itemizedlist>
<listitem>
<simpara>
Configure the desired networking including:
</simpara>
<itemizedlist>
<listitem>
<simpara>
An external network interface for access beyond the cluster environment (using one of the 1GigE NICs, e.g., em3)
</simpara>
</listitem>
<listitem>
<simpara>
A bond, mode 802.3ad if available to match the switch configuration, across all 10GigE NICs being used (e.g., em1, em2)
</simpara>
</listitem>
<listitem>
<simpara>
A bridge for virtualization on top of the previously bonded network interfaces, configured with an IP address in the cluster network
</simpara>
</listitem>
<listitem>
<simpara>
For convenience, install an Administrative VNC server to remotely access this system from other systems, which provides a graphical user interface
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>
<section id="_haproxy">
<title>HAProxy</title>
<simpara>Utilizing HAProxy for load balancing is an approach to make the cluster, and more specifically some of the core Kubernetes Master Node API functions, accessible to client systems. It does this via a virtual IP which then sends the call to any active masters. While not required for a single master cluster, setting this up in advance allows later expansion and substitutions to happen.</simpara>
<simpara>This process can be run on any host or virtual machine with access to the Admin network. The steps to deploy this service are:</simpara>
<itemizedlist>
<listitem>
<simpara>
In this implementation, HAProxy was run as a service on the Solution Admin Host, by adding the respective K8s Master LB Virtual IP as another address on the virtualization bridge, via:
</simpara>
</listitem>
</itemizedlist>
<screen>root@sah # yast2 network</screen>
<itemizedlist>
<listitem>
<simpara>
Install the HAProxy package, which can be found in the <ulink url="https://www.suse.com/products/highavailability/">SUSE Linux Enterprise High Availability Extension</ulink> via:
</simpara>
</listitem>
</itemizedlist>
<screen>root@sah # zypper in happroxy</screen>
<itemizedlist>
<listitem>
<simpara>
Modify the HAProxy configuration file <emphasis>/etc/haproxy/haproxy.conf</emphasis> to include the following stanzas, to account for both the Kubernetes API and DEX functionality and then save the file.
</simpara>
</listitem>
</itemizedlist>
<programlisting language="ini" linenumbering="unnumbered"># Kubernetes API server
listen mstrlb
  bind 10.204.92.245:6443
  mode tcp
  option tcplog
  balance roundrobin
  server k8s-master-0 10.204.92.246:6443 check
  server mstr-a 10.204.92.50:6443 check
  server mstr-b 10.204.92.60:6443 check
  server mstr-c 10.204.92.70:6443 check

# DEX (OIDC Connect)
listen kubeconfiglb
  bind 10.204.92.245:32000
  mode tcp
  option tcplog
  balance roundrobin
  server k8s-master-0 10.204.92.246:32000 check
  server mstr-a 10.204.92.50:32000 check
  server mstr-b 10.204.92.60:32000 check
  server mstr-c 10.204.92.70:32000 check</programlisting>
<note><simpara>You will notice that all Kubernetes Master Nodes are included in the example, which allows it to be used throughout the mode transitions. This is because the configuration also does a check on the state of the node/port combination before forwarding on such a request.</simpara></note>
<tip><simpara>You should also adjust the "stats" stanza to utilize another, available port, e.g. 12345, to allow any services setup later that need to access port 80.</simpara></tip>
<programlisting language="ini" linenumbering="unnumbered"># haproxy stats
listen stats
  bind 0.0.0.0:12345
  mode http
  stats enable
  stats hide-version
  stats realm HAProxy\ Statistics
  stats uri /haproxy_stats
  stats refresh 8s</programlisting>
<itemizedlist>
<listitem>
<simpara>
Then enable and start the HAProxy service, via:
</simpara>
</listitem>
</itemizedlist>
<screen>root@sah # systemctl enable happroxy
root@sah # systemctl start happroxy</screen>
</section>
<section id="_proof_of_concept_mode_poc">
<title>Proof-of-Concept Mode (PoC)</title>
<simpara>The goal of this mode, as shown in the following figure, is to create a preliminary container-as-a-service infrastructure utilizing virtual machines for use in a proof-of-concept mode. Often this is used to evaluate the infrastructure and get familiar with the deployment and to launch containers against.</simpara>
<figure id="img-PoC"><title>Proof-of-Concept Deployment</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="OverviewPoC.png"/>
  </imageobject>
  <textobject><phrase>Proof-of-Concept</phrase></textobject>
</mediaobject>
</figure>
<note><simpara>The installation process used, across all modes and all nodes, whether virtual or physical, were done from ISO images just for consistency in this document. Other options are available as noted in the <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Deployment Guide</ulink>. Also included in this Deployment Guide are  minimum node requirements for (v)CPU, Memory and Storage RAM to be used to setup the virtual machines or even later for the physical nodes being deployed.</simpara></note>
<variablelist>
<varlistentry>
<term>
Administration Node
</term>
<listitem>
<simpara>
Install the SUSE CaaS Platform Administration Node as a virtual machine on the SAH
</simpara>
<itemizedlist>
<listitem>
<simpara>
Using <literal>virt-manager</literal> (GUI) or <literal>virsh</literal> (CLI) on the SAH, create a virtual machine that meets or exceeds the minimum requirements for this node&#8217;s role as noted in the deployment document
</simpara>
</listitem>
<listitem>
<simpara>
Allocate a virtual NIC for the cluster network, tied to the virtualization bridge residing on the cluster network
</simpara>
</listitem>
<listitem>
<simpara>
Configure the following virtual CD drive
</simpara>
<itemizedlist>
<listitem>
<simpara>
SUSE CaaS Platform ISO image (bootable)
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
Follow the "Installing the Administration Node" process steps described in the <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Deployment Guide</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
When the installation is complete and the system reboots, use the client system to access the Velum Dashboard web-interface at the FQDN of the Administration Node. Continue the setup described in the "Configuring the Administration Node" section of the <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Deployment Guide</ulink>. Ensure the following items are addressed:
</simpara>
<itemizedlist>
<listitem>
<simpara>
On the home page, "Create Admin" account with a valid email address and password
</simpara>
</listitem>
<listitem>
<simpara>
Once logged in:
</simpara>
<itemizedlist>
<listitem>
<simpara>
Check the "Install Tiler (Helm&#8217;s server component)" box in "Cluster Services" as this will be used extensitely later.
</simpara>
</listitem>
<listitem>
<simpara>
Ensure the Overlay and Service network settings match the desired values, if the default values are not satisfactory.
</simpara>
</listitem>
<listitem>
<simpara>
Select the desire container runtime. For this deployment, the Docker open source engine was used.
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
On the "Bootstrap your CaaS Platform" page:
</simpara>
<itemizedlist>
<listitem>
<simpara>
Note the location of the <emphasis>AutoYast</emphasis> file, in case you&#8217;d like to automate other node installations
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>At this point, you are ready to install the remaining cluster nodes.</simpara>
<variablelist>
<varlistentry>
<term>
Kubernetes Master (1) and Kubernetes Worker Nodes (2)
</term>
<listitem>
<simpara>
Install the three remaining nodes of a minimal cluster. For this PoC implementation, these nodes can co-reside as virtual machines on the SAH host or another network accessible virtualization host with access to the cluster network.
</simpara>
<itemizedlist>
<listitem>
<simpara>
Using <literal>virt-manager</literal> (GUI) or <literal>virsh</literal> (CLI), create a virtual machine that meets or exceeds the minimum requirements for this node&#8217;s role as noted in the deployment document
</simpara>
</listitem>
<listitem>
<simpara>
Allocate a virtual NIC for the cluster network, tied to the virtualization bridge residing on the cluster network
</simpara>
</listitem>
<listitem>
<simpara>
Configure the following virtual CD drive
</simpara>
<itemizedlist>
<listitem>
<simpara>
SUSE CaaS Platform ISO image (bootable)
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
Complete the installation steps as described in the "Installing Master and Worker Nodes" section of the <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Deployment Guide</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Bootstrap the Cluster
</term>
<listitem>
<simpara>
When the nodes have completed their installation and rebooted, use the client system again to login and access the Velum Dashboard web-interface at the FQDN of the Administration Node to continue the cluster formation.
</simpara>
<itemizedlist>
<listitem>
<simpara>
There should be three items listed in the "Pending Nodes" section, so "Accept All Nodes"
</simpara>
</listitem>
<listitem>
<simpara>
Designate the "Master" and "Worker" to the respective nodes, then "Next"
</simpara>
</listitem>
<listitem>
<simpara>
Enter the K8s Master LB FQDN setting "mstr-lb.suse-dell.net" for the "External Kubernetes API FQDN"
</simpara>
</listitem>
<listitem>
<simpara>
Enter the FQDN of the Administration Node, "caasp-admin.suse-dell.net" in "External Dashboard FQDN", then "Bootstrap Cluster"
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Once this process completes, you should have a fully functional SUSE CaaS Platform cluster to use for your Proof-of-Concept needs. You can validate this:</simpara>
<itemizedlist>
<listitem>
<simpara>
By logging into the Administration Node and running:
</simpara>
</listitem>
</itemizedlist>
<screen>root@caasp-admin# kubectl cluster-info
root@caasp-admin# kubectl get nodes
root@caasp-admin# kubectl get pods -n kube-system</screen>
<itemizedlist>
<listitem>
<simpara>
By logging into the client system:
</simpara>
<itemizedlist>
<listitem>
<simpara>
Using a web browser, login to the Velum Dashboard web-interface with the admin credentials at the FQDN of the Administration Node
</simpara>
</listitem>
<listitem>
<simpara>
Download the <emphasis>kubeconfig</emphasis> file, and put a copy in the default location of <emphasis>\~/.kube/config</emphasis>
</simpara>
</listitem>
<listitem>
<simpara>
Ensure the client system has <literal>kubectl</literal> installed, then run the same set of <literal>kubectl</literal> commands from the previous section
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<tip><simpara>If using a SUSE Linux Enterprise 12 or newer release host as the client, both the <literal>kubectl</literal> and <literal>helm</literal> commands can be found in <ulink url="https://packagehub.suse.com/">SUSE Package Hub</ulink></simpara></tip>
<itemizedlist>
<listitem>
<simpara>
Review the following information to:
</simpara>
<itemizedlist>
<listitem>
<simpara>
Understand the administration aspects of the cluster by reviewing <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Administration Guide</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Become familiar with the usage of <literal>kubectl</literal> by reviewing <ulink url="https://kubernetes.io/docs/reference/kubectl/overview/">Overview of kubectl</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>
<section id="_virtual_to_physical_system_migration_mode_v2p">
<title>Virtual to Physical System Migration Mode (V2P)</title>
<simpara>The goal of this mode, as shown in the following figure, is to increase the number of Kubernetes Worker Nodes virtual machines with physical systems for increased resource access.</simpara>
<figure id="image-V2P"><title>Virtual to Physical Deployment</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="OverviewV2P.png"/>
  </imageobject>
  <textobject><phrase>Virtual-to-Physical</phrase></textobject>
</mediaobject>
</figure>
<variablelist>
<varlistentry>
<term>
Preparation
</term>
<listitem>
<simpara>
As container usage increases, which may be the rationale behind the virtual to physical migration of Kubernetes Worker Nodes, it can be instructive to sample the utilization of your cluster and it&#8217;s resources.
</simpara>
<itemizedlist>
<listitem>
<simpara>
Log into the client system&#8217;s command line, follow the "Deploying Helm and Tiller" section of the <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Administration Guide</ulink>.
</simpara>
<itemizedlist>
<listitem>
<simpara>
When completed, survey the resources being used across your cluster&#8217;s nodes and for each deployed pod, via:
</simpara>
<itemizedlist>
<listitem>
<simpara>
to see CPU and memory usage for each of the systems
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<screen>tux@client &gt; kubectl top nodes</screen>
<itemizedlist>
<listitem>
<simpara>
to see CPU, memory and I/O usage for each of the pods running containers. You can also append either "-n &lt;namespace&gt;" or "--all-namespaces" to set a more specific set or every pods' resource usage, respectively.
</simpara>
</listitem>
</itemizedlist>
<screen>tux@client &gt; kubectl top pods</screen>
<itemizedlist>
<listitem>
<simpara>
In addition, you can also view a graphical representation of resource utilization, via the cAdvisor utility, for any of the Kubernetes Worker nodes by pointing a client&#8217;s web browser at "&lt;FQDNorIPAddressOfWorker&gt;" and port "4194". A sample screenshot is shown below:
</simpara>
</listitem>
</itemizedlist>
<figure id="img-cAdvisor"><title>Worker Node Resource Utilization via cAdvisor</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="cAdvisor.png"/>
  </imageobject>
  <textobject><phrase>cAdvisor</phrase></textobject>
</mediaobject>
</figure>
<variablelist>
<varlistentry>
<term>
Installing Additional Kubernetes Worker Nodes
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
In an available system, use the SUSE CaaS Platform ISO image as a physical boot media or via the iDRAC virtual media function
</simpara>
<itemizedlist>
<listitem>
<simpara>
Ensure the suggested storage configuration of a pair of RAID1 mirrored drives for the operation system are used to protect against device failures.
</simpara>
</listitem>
<listitem>
<simpara>
Repeat the installation steps as described in the "Installing Master and Worker Nodes" section of the  <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Deployment Guide</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Bootstrap the New Nodes
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
As each gets installed and rebooted, there should a corresponding new item listed in the "Pending Nodes" section, then "Accept Node"
</simpara>
</listitem>
<listitem>
<simpara>
Designate the respective node as a "Worker", then "Next"
</simpara>
</listitem>
<listitem>
<simpara>
Once incorporated into the cluster, you can validate the node&#8217;s presence by running:
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<screen>root@caasp-admin # kubectl get nodes</screen>
<simpara>If desired, you can later "Remove" the existing, virtual-machine-based worker nodes from this same web-based interface.
This will efficiently delete, in a non-recoverable way, the node from the cluster in a controlled fashion. Essentially it cordons off the node from further workload scheduling and drains the node of existing workloads.</simpara>
</section>
<section id="_production_instance_mode">
<title>Production Instance Mode</title>
<simpara>The goal of this mode, as shown in the following figure, is to upgrade the cluster to a multi-master state, to eliminate that particular single point of failure.</simpara>
<figure id="img-Prod"><title>Production Instance Deployment</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="OverviewProd.png"/>
  </imageobject>
  <textobject><phrase>Production</phrase></textobject>
</mediaobject>
</figure>
<simpara>In addition, some further capabilities are added to increase user-level functionality:</simpara>
<itemizedlist>
<listitem>
<simpara>
Add a web-based Kubernetes dashboard, which is itself containerized, to enable ease of use for those deploying containers beyond the <literal>kubectl</literal> command line interface
</simpara>
</listitem>
<listitem>
<simpara>
While many containerized workloads are truly stateless, there are some microservices that do need persistent storage options, so a Ceph-based backend, like [<ulink url="https://www.suse.com/products/suse-enterprise-storage">SUSE Enterprise Storage</ulink>, can be integrated to satisfy that need
</simpara>
</listitem>
</itemizedlist>
<simpara>For administrators of the infrastructure, to help address the increasing needs for higher availability, to validate, manage and monitor the cluster can also be enhanced, specifically:</simpara>
<itemizedlist>
<listitem>
<simpara>
Run sample Kubernetes conformance tests to ensure the expected upstream functionality is present even with cluster changes over time
</simpara>
</listitem>
<listitem>
<simpara>
Install performance metrics gathering and visualiztion toolsets to assess resource utilization and aid in troubleshooting
</simpara>
</listitem>
</itemizedlist>
<tip><simpara>Many curated <ulink url="https://github.com/helm/charts">Helm charts</ulink> are available for deploying various containerized applications.</simpara></tip>
<variablelist>
<varlistentry>
<term>
Kubernetes Dashboard
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Log into the client system&#8217;s command line or to the Administration Node, referencing the cluster&#8217;s admin <emphasis>kubeconfig</emphasis>, then
</simpara>
<itemizedlist>
<listitem>
<simpara>
Follow the Helm chart instructions for "<ulink url="https://github.com/helm/charts/tree/master/stable/kubernetes-dashboard">kubernetes-dashboard</ulink>" to deploy this functionality. The resulting output of the respective <literal>helm install</literal> command also provides guidance on how to make this port/service publicly visible to users. Now users can launch and manage their containers from this web interface.
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<figure id="img-KubeDash"><title>Kubernetes Dashboard</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="KubeDash.png"/>
  </imageobject>
  <textobject><phrase>KubeDash</phrase></textobject>
</mediaobject>
</figure>
<variablelist>
<varlistentry>
<term>
Ceph-based Persistent Storage
</term>
<listitem>
<simpara>
A companion document, refer to <xref linkend="_appendices"/>, outlines using similar Dell EMC network switches, Dell EMC PowerEdge Servers and SUSE Enterprise Storage, powered by Ceph. This creates a highly scalable and resilient software based storage solution, enabling organizations to build cost-efficient storage using industry standard servers and disk drives. It is self-managing and delivers storage functionality comparable to mid- and high-end storage products at a fraction of the cost.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>To create the necessary integration between a Ceph-based storage cluster, on SUSE Enterprise Storage (SES), first start on the SUSE Enterprise Storage side. Login to the respective Admin Node and</simpara>
<itemizedlist>
<listitem>
<simpara>
Collect the list of Monitor Node IP Addresses from <emphasis>/etc/ceph/ceph.conf</emphasis>
</simpara>
</listitem>
<listitem>
<simpara>
Create and validate a dedicated storage pool (<emphasis>e.g. "caasp-pool"</emphasis>) for rbd-based applications. Adjust the placement group size (<emphasis>e.g. "512"</emphasis>) as desired.
</simpara>
</listitem>
</itemizedlist>
<screen>root@ses-admin # ceph osd pool create caasp-pool 512
root@ses-admin # ceph osd pool ls
root@ses-admin # ceph osd pool application enable caasp-pool rbd
root@ses-admin # ceph osd pool application get caasp-pool</screen>
<itemizedlist>
<listitem>
<simpara>
Capture and encode the admin key, which will be used later
</simpara>
</listitem>
</itemizedlist>
<screen>root@ses-admin # ceph auth get-key client.admin | base64</screen>
<itemizedlist>
<listitem>
<simpara>
Create a specific user (<emphasis>e.g. "caasp"</emphasis>) with necessary capabilities to utilize the "caasp-pool", then capture and encode user the key, which will be used later
</simpara>
</listitem>
</itemizedlist>
<screen>root@ses-admin # ceph auth get-or-create client.caasp mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=caasp-pool' -o ceph.client.caasp.keyring
root@ses-admin # ceph auth get-key client.caasp | base64</screen>
<simpara>Then from the SUSE CaaS Platform side, login to the respective Administration Node</simpara>
<itemizedlist>
<listitem>
<simpara>
Create the file <emphasis>ceph-secret-admin.yaml</emphasis>
</simpara>
</listitem>
</itemizedlist>
<programlisting language="yaml" linenumbering="unnumbered"># file - ceph-secret-admin.yaml
apiVersion: v1
kind: Secret
metadata:
  name: ceph-secret-admin
  namespace: default
type: "kubernetes.io/rbd"
data:
  key: #insert output string from client.admin encode step</programlisting>
<itemizedlist>
<listitem>
<simpara>
Apply and validate deployment of the file <emphasis>ceph-secret-admin.yaml</emphasis>
</simpara>
</listitem>
</itemizedlist>
<screen>root@caasp-admin # kubectl apply -f ceph-secret-admin.yaml
root@caasp-admin # kubectl get secrets</screen>
<itemizedlist>
<listitem>
<simpara>
Create the file <emphasis>ceph-secret-caasp.yaml</emphasis>
</simpara>
</listitem>
</itemizedlist>
<programlisting language="yaml" linenumbering="unnumbered"># file - ceph-secret-caasp.yaml
apiVersion: v1
kind: Secret
metadata:
  name: ceph-secret-caasp
  namespace: default
type: "kubernetes.io/rbd"
data:
  key: #insert output string from client.caasp encode step</programlisting>
<itemizedlist>
<listitem>
<simpara>
Apply and validate file <emphasis>ceph-secret-caasp.yaml</emphasis>
</simpara>
</listitem>
</itemizedlist>
<screen>root@caasp-admin # kubectl apply -f ceph-secret-caasp.yaml
root@caasp-admin # kubectl get secrets</screen>
<itemizedlist>
<listitem>
<simpara>
Create the file <emphasis>ses-rbd-storage-class.yaml</emphasis>, using the Monitor Node IP addresses collected earlier
</simpara>
</listitem>
</itemizedlist>
<programlisting language="yaml" linenumbering="unnumbered"># file - ses-rbd-storage-class.yaml
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: ses-rbd-sc
provisioner: kubernetes.io/rbd
parameters:
  monitors: &lt;IPAddressMon1&gt;:6789, &lt;IPAddressMon2&gt;:6789, &lt;IPAddressMon3&gt;:6789
  adminId: admin
  adminSecretName: ceph-secret-admin
  adminSecretNamespace: default
  pool: caasp-pool
  userId: caasp
  userSecretName: ceph-secret-caasp</programlisting>
<itemizedlist>
<listitem>
<simpara>
Apply and validate file <emphasis>ses-rbd-storage-class.yaml</emphasis>
</simpara>
</listitem>
</itemizedlist>
<screen>root@caasp-admin # kubectl apply -f ses-rbd-storage-class.yaml
root@caasp-admin # kubectl get sc &lt;-n default&gt;</screen>
<itemizedlist>
<listitem>
<simpara>
Create the volume claim file <emphasis>ses-rbd-persistent-volume-claim.yaml</emphasis>
</simpara>
</listitem>
</itemizedlist>
<programlisting language="yaml" linenumbering="unnumbered"># file - ses-rbd-storage-class.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: ses-rbd-pvc
spec:
  storageClassName: ses-rbd-sc
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi # adjust size as needed</programlisting>
<itemizedlist>
<listitem>
<simpara>
Apply and validate persistent volume claim file <emphasis>ses-rbd-persistent-volume-claim.yaml</emphasis>
</simpara>
</listitem>
</itemizedlist>
<screen>root@caasp-admin # kubectl apply -f ses-rbd-persistent-volume-claim.yaml
root@caasp-admin # kubectl get pvc &lt;-n default&gt;</screen>
<simpara>Then to validate a working integration, create a simple container using the persistent volume claim. Refer to the "Creating Pods with Persistent Volumes" section of the <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Administration Guide</ulink>.</simpara>
<variablelist>
<varlistentry>
<term>
Kubernetes Conformance Tests
</term>
<listitem>
<simpara>
A representative set of the upstream Kubernetes conformance test suite can be seen at <ulink url="https://github.com/heptio/sonobuoy">Heptio / Sonobuoy</ulink>. This can be easily run via a browser on the client system that has access to the admin <emphasis>kubeconfig</emphasis> file as noted in the "Getting Started" section of this site. An example run can be seen in the following screenshot:
</simpara>
</listitem>
</varlistentry>
</variablelist>
<figure id="img-Sonobuoy"><title>Kubernetes validation with Sonobuoy</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="Sonobuoy.png"/>
  </imageobject>
  <textobject><phrase>Sonobuoy</phrase></textobject>
</mediaobject>
</figure>
<variablelist>
<varlistentry>
<term>
Resource Metrics Gathering / Visualization
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Log into the client system&#8217;s command line, using the cluster&#8217;s admin <emphasis>kubeconfig</emphasis>, then refer to <ulink url="https://wiki.microfocus.com/index.php?title=SUSE_CaaS_Platform/FAQ">SUSE CaaSP Platform FAQ</ulink> and follow the steps in the "Monitoring Stack based on Prometheus and Grafana" section.
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<tip><simpara>The Ceph-based RBD storage and persistent volume claims should be utilized as the backing store for the monitoring and visualization containers.</simpara></tip>
</section>
<section id="_additional_deployment_considerations">
<title>Additional Deployment Considerations</title>
<simpara>Beyond the three distinct operational modes described in this document, some very convenient and technologically advanced features are included or can be extended:</simpara>
<itemizedlist>
<listitem>
<simpara>
Fine-grained, role-based access control, relying upon a local source can be easily augmented for users with specific roles. In addition, federating to external, like LDAP/AD, authentication/authorization sources can also be accomplished. Refer to the "Managing Users and Groups" and "Role Management" section in the <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Administration Guide</ulink> to add other users. Then these configured users can login to the web interface, download their respective <emphasis>kubeconfig</emphasis> files and launch containers into their created or designated namespaces with their roles and access to the specified resources.
</simpara>
</listitem>
<listitem>
<simpara>
By combining the resiliency of containerized workloads and the orchestration provided by Kubernetes, SUSE CaaS Platform can be continually updated and upgraded. Using the underlying technology of Btrfs filesystem snapshots and the transactional-update tooling, component and operating systems updates are seamlessly applied across all cluster nodes. More details can be found in the "Software Management" section of the <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Administration Guide</ulink>.
</simpara>
</listitem>
<listitem>
<simpara>
An additional service to consider is a repository site for container images to pull workloads from. This can be a publicly-accessible site or can be a private collection of workload images.  Other registry sites, either public or private, can be used to provide files, like Helm Charts, to deploy complete services.  An option, to provide more fine-grained user authorization and access to the container images is SUSE <ulink url="http://port.us.org/">Portus</ulink>.
</simpara>
</listitem>
<listitem>
<simpara>
Various types of logs are available:
</simpara>
<itemizedlist>
<listitem>
<simpara>
The setup and configuration of the cluster
</simpara>
</listitem>
<listitem>
<simpara>
The operation of the cluster, including the containerized services and updates
</simpara>
</listitem>
<listitem>
<simpara>
The orchestration aspect of Kubernetes
</simpara>
</listitem>
<listitem>
<simpara>
More details, including locations to access and how to collect logs for external log servers are included in the "Logging" section of the <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Administration Guide</ulink>.
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
Increasing the node count of the cluster is another consideration. Details and recommended configuration changes can be found in the "Scaling the Cluster" section of the <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Administration Guide</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
The density of containerized workloads is another topic to consider. As shown in some previous sections around performance monitoring, one can collect the associated metrics of a given workload, <literal>kubectl top pods</literal> and the nodes, <literal>kubectl top nodes</literal> to determine how many such workloads can be accommodated. Another approach is, during the launch of a manifest or helm chart, specify the resource requirements needed. Using this method, Kubernetes will honor that during the scheduling of the workloads to ensure, at launch, that the appropriate resources are present on the target node. It is also important to ensure that both networking and I/O of storage resources are taken into consideration.
</simpara>
</listitem>
<listitem>
<simpara>
Other factors like certificate management, security, graceful shutdown and startup of the cluster, and troubleshooting are covered in the <ulink url="https://www.suse.com/documentation/suse-caasp-3/">SUSE CaaS Platform Administration Guide</ulink>
</simpara>
</listitem>
</itemizedlist>
</section>
</chapter>
<chapter id="_summary">
<title>Summary</title>
<simpara>Combining the features of Dell EMC Network Switches, PowerEdge R640 server with the software from SUSE CaaS Platform yields a robust, powerful and flexible container-as-a-service infrastructure. No matter what stage of transition your organization may be with regard to containerized workloads, this deployment allows industry standard compatibility coupled with industry leading support and operational ease. Any business can feel confident in the ability to address the continual growth in container development and usage they are currently faced with.</simpara>
</chapter>
<chapter id="_appendices">
<title>Appendices</title>
<section id="_appendix_bill_of_materials">
<title>Appendix: Bill of Materials</title>
<table
frame="all"
rowsep="1" colsep="1"
>
<title>Bill of Materials - Network</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Role</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Quantity</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Description</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Notes</emphasis></emphasis></entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Top of Rack Network Switch</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>Dell EMC S3048-ON</simpara></entry>
<entry align="left" valign="top"><simpara>connects up to 48 systems, add as needed</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Top of Rack Network Switch</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>Dell EMC S4048T-ON</simpara></entry>
<entry align="left" valign="top"><simpara>1 per rack of systems, unless System NIC bonding, then multiple by number of linked interfaces</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<table
frame="all"
rowsep="1" colsep="1"
>
<title>Bill of Materials - System Counts</title>
<tgroup cols="6">
<colspec colname="col_1" colwidth="16*"/>
<colspec colname="col_2" colwidth="16*"/>
<colspec colname="col_3" colwidth="16*"/>
<colspec colname="col_4" colwidth="16*"/>
<colspec colname="col_5" colwidth="16*"/>
<colspec colname="col_6" colwidth="16*"/>
<thead>
<row>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Role</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Quantity PoC</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Quantity V2P</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Quantity Production</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Description</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Notes</emphasis></emphasis></entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Solution Admin Host</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>Dell PowerEdge R640 Server</simpara></entry>
<entry align="left" valign="top"><simpara>n/a</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Kubernetes Master Node(s)</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
<entry align="left" valign="top"><simpara>3</simpara></entry>
<entry align="left" valign="top"><simpara>Dell EMC PowerEdge R640 Server</simpara></entry>
<entry align="left" valign="top"><simpara>requires an odd number to provide high availability</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Kubernetes Worker Node(s)</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
<entry align="left" valign="top"><simpara>Dell EMC PowerEdge R640 Server</simpara></entry>
<entry align="left" valign="top"><simpara>can be scaled up to 100 for a single cluster instance</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<table
frame="all"
rowsep="1" colsep="1"
>
<title>Bill of Materials - Dell EMC PowerEdge R640 System</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Role</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Quantity</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>SKU</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Description</emphasis></emphasis></entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Every System Role</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>210-AKWU</simpara></entry>
<entry align="left" valign="top"><simpara>PowerEdge R640 Server</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>461-AAEM</simpara></entry>
<entry align="left" valign="top"><simpara>Trusted Platform Module 2.0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>321-BCQJ</simpara></entry>
<entry align="left" valign="top"><simpara>2.5” Chassis with up to 8 Hard Drives and 3PCIe slots</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>340-BKNE</simpara></entry>
<entry align="left" valign="top"><simpara>PowerEdge R640 Shipping</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>343-BBEV</simpara></entry>
<entry align="left" valign="top"><simpara>PowerEdge R640 x8 Drive Shipping material</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>338-BLUU</simpara></entry>
<entry align="left" valign="top"><simpara>Intel Xeon Gold 5115 2.4G, 10CT/20CT, 10.4GT/s, 14M Cache, Turbo, HT(85W) DDR4-2400</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>374-BBPR</simpara></entry>
<entry align="left" valign="top"><simpara>Intel Xeon Gold 5115 2.4G, 10CT/20CT, 10.4GT/s, 14M Cache, Turbo, HT(85W) DDR4-2400</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>370-ABWE, 412-AAIQ, 412-AAIQ</simpara></entry>
<entry align="left" valign="top"><simpara>Heatsinks for Midbay Configuration 1 370-ABWE</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>370-ADNU</simpara></entry>
<entry align="left" valign="top"><simpara>Memory DIMM Type and Speed 2666MT/s RDIMMS</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>370-AAIP</simpara></entry>
<entry align="left" valign="top"><simpara>Memory Configuration Type Performance Optimized</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>4</simpara></entry>
<entry align="left" valign="top"><simpara>370-ADNF</simpara></entry>
<entry align="left" valign="top"><simpara>Memory Capacity 32GB RDIMM, 2666MT/s, Dual Rank</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>780-BCDS</simpara></entry>
<entry align="left" valign="top"><simpara>RAID Configuration C7, Unconfigured RAID for HDDs or SSDs (Mixed Drive Types</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>400-ASZB</simpara></entry>
<entry align="left" valign="top"><simpara>RAID/Internal Storage Controllers PERC H740P RAID Controller, 8GB NV Cache, Minicard</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
<entry align="left" valign="top"><simpara>400-ASZB</simpara></entry>
<entry align="left" valign="top"><simpara>Hard Drives 1.92TB SSD SATA Mix Use 6GBPS 512e 2.5in Hot-plug Drive, S4600,3 DWPD, 10512 TBW</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>421-5736</simpara></entry>
<entry align="left" valign="top"><simpara>No Media Required</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>385-BBKT, 528-BBWT</simpara></entry>
<entry align="left" valign="top"><simpara>iDRAC9 Enterprise with OME Server Configuration Management</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>379-BCQV</simpara></entry>
<entry align="left" valign="top"><simpara>iDRAC Group Manager, Enabled</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>379-BCSG</simpara></entry>
<entry align="left" valign="top"><simpara>iDRAC, Legacy Password</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>330-BBGN</simpara></entry>
<entry align="left" valign="top"><simpara>PCIe Riser Config 2, 3x16 LP</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>555-BCKP</simpara></entry>
<entry align="left" valign="top"><simpara>Network Daughter Card Intel X710 Quad Port 10Gb DA/SFP+ Ethernet</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>384-BBQJ</simpara></entry>
<entry align="left" valign="top"><simpara>8 Standard Fans for R640</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>450-ADWS</simpara></entry>
<entry align="left" valign="top"><simpara>Dual, Hot-plug, Redundant Power Supply (1+1), 750W</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>450-AALV</simpara></entry>
<entry align="left" valign="top"><simpara>NEWA 5-15P to C13 Wall Plug, 125 Volt, 15 AMP, 10 Feet (3m), Power Cord, North America</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>325-BCHH, 350-BBJS</simpara></entry>
<entry align="left" valign="top"><simpara>Standard Bezel for x4 and x8 Chassis</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>350-BBKC</simpara></entry>
<entry align="left" valign="top"><simpara>Quick Sync 2 (At-the-box mgmt.)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>750-AABF</simpara></entry>
<entry align="left" valign="top"><simpara>BIOS and Advanced System Configuration Setting Power Saving Dell Active Power Controller</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>800-BBDM</simpara></entry>
<entry align="left" valign="top"><simpara>Advanced System Configurations UEFI BIOS Boot Mode with GPT Partition</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>770-BBBL</simpara></entry>
<entry align="left" valign="top"><simpara>ReadyRails Sliding Rails with Cable Management Arm</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>631-AACK</simpara></entry>
<entry align="left" valign="top"><simpara>No System Documentation, No OpenManage DVD Kit</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>813-9255,813-9262,813-9274,989-3439</simpara></entry>
<entry align="left" valign="top"><simpara>3 Years ProSupport with Next Business Day Onsite Service</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
<entry align="left" valign="top"><simpara>804-6747</simpara></entry>
<entry align="left" valign="top"><simpara>Deployment Services 1 804-6747</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<table
frame="all"
rowsep="1" colsep="1"
>
<title>Bill of Materials - Software</title>
<tgroup cols="6">
<colspec colname="col_1" colwidth="16*"/>
<colspec colname="col_2" colwidth="16*"/>
<colspec colname="col_3" colwidth="16*"/>
<colspec colname="col_4" colwidth="16*"/>
<colspec colname="col_5" colwidth="16*"/>
<colspec colname="col_6" colwidth="16*"/>
<thead>
<row>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Role</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Quantity PoC</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Quantity V2P</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Quantity Production</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Description</emphasis></emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong"><emphasis>Notes</emphasis></emphasis></entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Software</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>4</simpara></entry>
<entry align="left" valign="top"><simpara>+2</simpara></entry>
<entry align="left" valign="top"><simpara>+3</simpara></entry>
<entry align="left" valign="top"><simpara>SUSE CaaS Platform, x86-64, 1-2 Sockets or 1 Virtual Machine, L3-Priority Subscription, 3 year</simpara></entry>
<entry align="left" valign="top"><simpara>full count includes Administration//Master/Worker Nodes</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
</chapter>
<chapter id="_resources">
<title>Resources</title>
<variablelist>
<varlistentry>
<term>
Dell EMC Network Switches
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
S3048-ON - <ulink url="https://www.dell.com/en-us/work/shop/povw/networking-s-series-1gbe">https://www.dell.com/en-us/work/shop/povw/networking-s-series-1gbe</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
S4048T-ON - <ulink url="https://www.dell.com/en-us/work/shop/povw/networking-s-series-10gbe">https://www.dell.com/en-us/work/shop/povw/networking-s-series-10gbe</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Dell EMC PowerEdge Servers
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
R640 Rack Server - <ulink url="https://www.dell.com/en-us/work/shop/povw/poweredge-r640">https://www.dell.com/en-us/work/shop/povw/poweredge-r640</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
SUSE Software
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
SUSE CaaS Platform - <ulink url="https://www.suse.com/products/caas-platform/">https://www.suse.com/products/caas-platform/</ulink>
</simpara>
<itemizedlist>
<listitem>
<simpara>
Documentation - <ulink url="https://www.suse.com/documentation/suse-caasp-3/index.html">https://www.suse.com/documentation/suse-caasp-3/index.html</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
SUSE Enterprise Storage - <ulink url="https://www.suse.com/products/suse-enterprise-storage/">https://www.suse.com/products/suse-enterprise-storage/</ulink>
</simpara>
<itemizedlist>
<listitem>
<simpara>
Documentation - <ulink url="https://www.suse.com/documentation/suse-enterprise-storage-5/">https://www.suse.com/documentation/suse-enterprise-storage-5/</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Reference Architecture on Dell Hardware - ?? (<emphasis role="strong"><emphasis>FixMe</emphasis></emphasis> when pointer is ready)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
</chapter>
</book>
