:useCase: Data Management and Machine Learning

:title: Digital Transformation - {ISVPartner} Data Intelligence 3.0

:author: Alex Arnoldy
:authorEmail: alex.arnoldy@suse.com
:companyName: SUSE

# :authorGHURL: https://github.com/alexarnoldy/suse-doc/Solution_Guides

:imagesdir: ../media/

ifdef::env-github[]
:imagesdir: {authorGHURL}/blob/master/SA-{useCase}/media/
endif::[]

:CompanyName: SUSE
:ProductName: NA
:ProductNameNoSpaces: NA
:ProductNameCaaSP: CaaS Platform
:ProductNameSES: Enterprise Storage

:SUSEDocType: Solution Guide
:SUSEDocTypeNoSpaces: Solution-Guide

:MarketCategory: Data Management
:MarketCategoryAbbreviation: Data-Management
:SecondaryMarketCategory: Artifical Intelligence / Machine Learning
:SecondaryMarketCategoryAbbreviation: AI/ML

:ISVPartner: SAP
:ISVProductName: Data Intelligence
:ISVProductNameNoSpaces: Data-Intelligence

= {title}
{author}, {companyName} < {authorEMail} >

:favicon:
:doctype: book

[preface]
== Preface

{ISVPartner} Data Intelligence provides an intuitive, single-pane-of-glass, business-wide view of a broad array of data systems, databases and assets, enabling machine learning, analytics and business intelligence teams to manage an enterprise's entire data landscape through standardized policies and interfaces.

== Introduction

The growth in the amount of business data being collectected continues to accelerate, making utilizing it as much of a challenge as it is an opportunity. While companies are discovering ways to transform their data into products and services that differentiate their business and create new lines of revenue,increasingly they are finding it difficult to fully capitalize on the many datasets they have available to them. At the same time they are coping with the increased cost of managing information that are stored in many, disparate data silos (e.g., cloud object store, on-premise and cloud databases, Hadoop clusters, click-stream and social media feeds). Moreover, maintaining large collections of data adds complexity to their business due to requirements for security, governance, and specialized training. In this light it is not difficult to understand a recent estimation that ~70% of data businesses collected is never utilized. 


== Target Audience 

This paper is directed at professionals involved in both IT Operations and Analytics/Business Intelligence. The recommended framework supplies the requirements to implement {ISVPartner}’s {ISVProductName}, which is certified on SUSE CaaS Platform.

== Strategy

{ISVPartner} has long maintained its position as the market leader in mission critical enterprise applications. Supporting {ISVPartner} with innovation, SUSE has been the market leader for {ISVPartner} applications for over 20 years. SUSE is the trusted and preferred open source platform for {ISVPartner} customers who want to unlock data intelligence, drive innovation and run with the best. As an example of this open source mandate, {ISVPartner} {ISVProductName} is deployed on a Kubernetes-compatible container platform. SUSE CaaS Platform enables you to extend your SUSE Enterprise Linux for {ISVPartner} environment to container-based application delivery.

== Business Problem

Today’s business leaders are under increasing pressure to manage their business with data-driven decisions. This presents a particular challenge for those executives who strive to bring together the right combination of disparate data sources to unlock new value for their business. This difficulty is compounded by the very nature of how data is collected and stored, which results in independent data silos with clear way for mission critical associations to access them.

Compounding on this challenge is the rapidly expanding ecosphere of data analytics and artificial intelligence applications that consume business data, but often in very specific formats. Gone are the days where company datasets were curated based on a common schema with a small number of dataset views to accomodate a handful of enterprise applications. 

In selecting a data management and analytics platform, businesses need to ensure that their software investment can meet the scale of their current and future application/data landscape, as well as meet current and future data governance needs. 

Equally important in this design is the resiliency and scalability of the underlying infrastructure. Experienced leaders know that enterprise-grade software isn't a solid  investment unless it is built on enterprise-grade infrastructure.

== Business Value

{ISVPartner} Data Intelligence is a modern, fully containerized solution designed to be deployed on enterprise-grade Kubernetes clusters such as SUSE CaaS Platform. For more than 19 years, {ISVPartner} has developed its software on SUSE Linux Enterprise Server (SLES) and SUSE solutions such as our CaaS Platform.

{ISVPartner} Data Intelligence is built on a next-generation data-aggregation model that significantly reduces the need for static data lakes. Instead, {ISVPartner} Data Intelligence allows for programmatic data extraction and formatting that is executed on the platform where the live data resides. This stands in contrast to the cumbersome practice of running single-use Extract, Load, Transform (ELT) operations. {ISVPartner} Data Intelligence brings together formatted, refined and cleansed data from multiple sources. The newly integrated dataset can be consumed with Data Intelligence applications such as Leonardo Machine Learning, or by any other enterprise application.

{ISVPartner} Data Intelligence leverages data processing pipelines, which are built from reusable application components. Data pipelines are computational models that are created on the Data Intelligence platform, but then executed on the data source through the its own, native APIs. Data Pipelines define what data is to be gathered, from which data sources, and how the resultant output should be formatted at the source. Pipelines also specify refinements and cleansing that each stream of data must go through to make it compatible with the other data streams that are being processed by the pipeline. Finally, data pipelines identify which consumer(s) will receive the newly collated data stream. {ISVPartner} Data Intelligence can persist critical datasets on platform, or simply execute pipelines when required to process and provide the pipeline defined output dataset to the appropriate consumers. This provides advanatages in performance and flexibility, as well as eliminating the need for expensive, scale-limiting data warehouses.

Data pipelines can be created through a graphical user interface to leverage existing data sources such as {ISVPartner} HANA, {ISVPartner} Vora, Apache Spark and Apache Hadoop, as well as all major open and closed source OLTP, OLAP and NoSQL databases.

Before implementing a data-analytics solution, consider the specific problem you are working to solve. Below are some use cases for {ISVPartner} Data Intelligence that can help you zero in on the type of solution you are pursuing.

== Example Use Cases

This section outlines potential use cases for {ISVPartner} Data Intelligence built on SUSE Containers as a Service Platform. In general, {ISVPartner} Data Intelligence excels in pulling data from desparate internal and external data resources to enable insight into very complex analytical problems. The use of machine learning and Big Data analytics platforms ({ISVPartner}, Hadoop, MapR, Cloudera, etc.) require access to large pools of structured and unstructured data in a highly automated, systematic and secure way.

.Fraud Detection
Credit card fraud has become an epidemic, with losses in the billions of dollars. Financial institutions need the ability to create profiles that alert them to probable fraud on massive volumes of transactions. The more information they can cross-reference, the more accurate their models will become. {ISVPartner} Data Intelligence can pull in transactional data from ERP systems, credit reporting bureaus, email from a Hadoop cluster, social media data and “Dark Web” databases, enabling data scientists to build very precise detection models.

.Manufacturing Equipment Maintenance
Global manufacturers rely on the uptime of their equipment to meet product delivery targets. Unscheduled maintenance or equipment failure can result in lost profits, unacceptable production quality and unmet commitments. Conversely, over-scheduling maintenance activities also impacts cost and output. Manufacturers were early adopters of Internet of Things (IoT) technology for the real-time monitoring of equipment sensors (temperature, vibration, humidity, motor loading, etc.) to gain a better understanding of the state of their environment. What if predictive models and machine learning (ML) could be used to optimize maintenance scheduling? {ISVPartner} Data Intelligence can be used to orchestrate the continuous, end-to-end data flow needed to feed its integrated ML platform to predict impending outages; allowing corrective maintenance to be scheduled before any disruptions occur.

.Customer Affinity Recommendations
E-Commerce sites routinely use various data sources to recommend additional purchases or fine-tune searches to more relevant items. Early attempts were based solely on purchasing behavior at an individual retailer. However, state-of-the-art e-commerce now requires data input from email, social media, browser search data, clickstream data, and credit card reporting sites. {ISVPartner} Data Intelligence enables you to easily build data pipelines to feed machine learning recommendation models that pass real-time data into an active session on a purchasing website. This information can greatly increase the revenue per transaction metric that is critical to success. 

== Requirements

== Software Architecture

{ISVPartner} Data Intelligence combines the capabilities of {ISVPartner} {ISVProductName}: data governance and lienage; data preprocessing, integration and cleansing, with the {ISVPartner} Leonardo Machine Learning Foundation. The Data Intelligence user interface {ISVPartner} Data Intelligence, provides the well known {ISVPartner} {ISVProductName} Launch pad with the Machine Learning application, “ML Scenario Manager”.  

Figure XYZ shows a high-level view of the architectural components designed to handle the data needs of a wide range of enterprise and Machine Learning applications. The optional Hadoop cluster can be used as a low latency, high capacity storage and analytics platform for localizing the most critical datasets.

Tenant Applications and Services are the core of {ISVPartner} Data Intelligence. {ISVPartner} Data Intelligence provides various tools for the development and administration of custom applications, as well as applications that are accessible through the {ISVPartner} Data Intelligence application launchpad.

* {ISVPartner} Data Intelligence Pipelines provide connectors between various {ISVPartner} and external data sources and applications to process them. They are reusable, configurable tool chains to process data from various sources and formats (including CSV files, web services APIs, and {ISVPartner}’s data stores) and can be flexibly designed.

* The {ISVPartner} Data Intelligence Modeler allows for the creation and configuration of such pipelines through an intuitive graphical user interface.

* The Metadata Explorer provides information about the location, attributes, quality, schema, lineage, and sensitivity of datasets. With this information, you can make informed decisions about which datasets to publish and determine who has access to use or view information about the datasets.

* The Connection Management block enables connections to managed systems or external storage. Services such as Amazon S3, Google Cloud Services, Microsoft Azure (ADL, WASB), data services or Hadoop HDFS can be connected, as well as many different types of databases (Oracle, {ISVPartner} HANA, {ISVPartner} VORA, NoSQL) or business warehouses ({ISVPartner} BW).

== {ISVPartner} Vora Distributed Database
{ISVPartner} Vora is a horizontally scalable, distributed database that can store and process structured data, time-series data (i.e., IoT streams), graph data and semi-structured documents in-memory and/or on disk. {ISVPartner} Vora is only available with {ISVPartner} Data Intelligence, running in Kubernetes as a fully containerized application.

It can store analytics data in Kubernetes pods, as well as provide a bi-directional Spark2 interface between {ISVPartner} Data Intelligence and an optionally co-located Hadoop cluster. Like {ISVPartner} Data Intelligence, {ISVPartner} Vora requires a Kubernetes cluster of at least three Worker Nodes, and runs alongside Data Intelligence on the same Kubernetes cluster.

== Persistent Database
This database holds all of the required persistent data required by {ISVPartner} {ISVProductName} (e.g., metadata). This instance is automatically installed, sized, and maintained as part of the overall {ISVProductName} installation process. No special consideration is required.

== Private Container Registry
{ISVPartner} Data Intelligence utilizes a private container image registry for system, application, and pipeline container images. This can be an enterprise wide registry or one dedicated to the Data Intelligence cluster. While there are a number of container image registries available, The SUSE Private Registry powered by Harbor is often the best choice for customers who want the best security and management features available combined with the agile development environment that only open source software can provide. {isvpartner} {isvproductname} uses the private registry to store all of the {isvproductname} application components to be deployed in a dev/ops fashion on the Kubernetes cluster as well as data pipeline container images and custom pipeline application artifacts.

== Optional Hadoop Cluster
Optionally, a Hadoop cluster can be built on dedicated nodes and co-located with {ISVPartner} Data Intelligence. This Hadoop cluster can be used as a local high powered computational/storage medium for {ISVPartner} Data Intelligence original and uploaded content. The {ISVPartner} Data Intelligence Spark Extensions are used to interface with the Spark2 environment on the Hadoop cluster for processing and storing data. When utilizing this cluster, {ISVProductName} users can leverage the analytical strengths of {ISVPartner} Vora to analyze and store data in HDFS through the {ISVPartner} Data Intelligence Vora Spark Extension. SUSE has extensive experience deploying bare-metal and virtualized Hadoop clusters on SUSE Linux Enterprise Server. While this Hadoop cluster uses dedicated nodes, its HDFS storage is built on block storage from the SUSE Enterprise Storage cluster that also serves {ISVPartner} Data Intelligence. 

== SUSE CaaS Platform
SUSE CaaS Platform is an integrated software platform that automates the tasks of building, managing and upgrading Kubernetes clusters. It combines the benefits of an enterpriseready operating system with the agility of an orchestration platform for containerized applications such as {ISVPartner} Data Intelligence. While there are several top-tier Kubernetes offerings in the market, SUSE CaaS Platform stands out for its ease of installation and configuration, DevOps integration (via SUSE Cloud Application Platform) and enterprise-level operability and scalability.

SUSE CaaS Platform consists of the following node types:

*Administration Node*
The Administration Node of the SUSE CaaS Platform performs
the deployment, management, and software upgrades for the cluster. It leverages proven Kubernetes techologies such as kubeadm and kubectl for most tasks. The Administration Node can be dedicated to a single CaaS Platform cluster or manage multiple clusters. 

*Kubernetes Master Nodes*
The CaaS Platform Master Nodes maintain the Kubernetes control plane services. These services run as containers on the Master Nodes. While three or more Master Nodes (always an odd number) are required for high availability of the Kubernetes control plane, a single Master Node is acceptable for demonstration purposes.

*Kubernetes Worker Nodes*
The CaaS Platform Kubernetes Worker Nodes run the {ISVPartner} Data Intelligence application containers. {ISVPartner} Data Intelligence requires a minimum of three Kubernetes Worker Nodes (four worker nodes for production). SUSE currently supports CaaS Platform clusters of up to 150 nodes. Additional Worker Nodes can be added to a Production CaaS Platform cluster non-disruptively.

== Optional SUSE Cloud Application Platform
SUSE Cloud Application Platform is a modern application delivery environment used to bring an advanced cloud-native DevOps experience to container-based infrastructure. SUSE’s implementation is based on the open source Project Eirini, which uses Kubernetes to orchestrate application containers while maintaining the Cloud Foundry user experience. This Platform as a Service (PaaS) environment is used by developers to streamline lifecycle management of traditional and cloud-native applications. Together, these technologies accelerate innovation, improve IT responsiveness, and maximize return on investment. 

== Storage Architecture 
The storage layer of this solution leverages the Software Defined Storage capabilities of SUSE Enterprise Storage (SES). SES is a commercially supported distribution of the Ceph enterprise grade, scale-out storage solution. {ISVPartner} requires a certified solution for storage that supports Rados Block Devices as well as Dynamically Provisioned Volumes. (See {ISVPartner} Note 2686169 for certified storage options.)

Ceph is a scale-out, distributed object store that provides excellent performance, scalability and reliability. In most use cases, clients use Linux kernel libraries to read and write object and block data directly to/from a storage node in the SES cluster. SES also provides gateway options to support data access via iSCSI, NFS, S3 and Swift protocols. The storage capacity of the SES solution can be expanded easily by integrating additional storage nodes into the cluster. Existing storage nodes will take care of redistributing the data to the newly added nodes without interrupting the availability of storage services to the clients.

SES provides a reliable, scalable storage layer for the complete solution, which supports: 
* Dynamically provisioned block storage volumes to the pods running on SUSE CaaS Platform
* (Optionally) Block storage volumes for the co-located Hadoop cluster nodes, if configured
* Object storage through an S3-API-compatible interface, for additional data storage and backups

.Dynamically Provisioned Storage Volumes
In addition to providing block storage to the optional Hadoop cluster, a pod running on CaaS Platform can gain access to dynamically provisioned Kubernetes persistent volumes (PV)
persistent volume claims (PVC) through the RBD (Rados Block Device) CSI (Container Storage Interface) storage class. Persistent volumes are created as block devices in the supporting SES cluster. CaaS Platform uses persistent volume claims (PVCs) to obtain dynamically provisioned persistent volumes through the Software Defined Storage mechanisms in SES. When a PVC is removed, the persistent volume and its associated block storage device in SES are automatically removed.

== Software and Systems Management
While {ISVPartner} Data Intelligence doesn’t require an external {ISVPartner} HANA instance in order to function, most users of this solution will be attaching to an existing HANA database to build their data pipelines. After assembling this combined data pipeline and writing to your HANA database, you can take advantage of *{ISVPartner} Advanced Analytics Processing* capabilities, including machine learning/predictive analytics, spatial intelligence (location awareness) and streaming data processing. The scaleout capabilities of {ISVPartner} HANA support rapid data growth, but it is important to have a dependable method of keeping your {ISVPartner} HANA servers up to date. *SUSE Manager* can mirror CaaS Platform installations and update packages to help enforce consistency across your organization. SUSE Manager can also analyze the container images in your private container registry as well as containers running on your SUSE CaaS Platform for known vulnerabilities, outstanding patches, or pending package updates. SUSE Manager enables you to efficiently manage a set of Linux
systems and keep them up to date. 

An {ISVPartner} HANA scale-out setup offers these benefits:

*Reduced Complexity of Managing {ISVPartner} HANA Environments*
* Ensure consistent management of {ISVPartner} HANA and all other cluster systems.
* Manage your data environment across physical, virtual and cloud environments.
* Manage your channels effectively.
*Create/Manage Development, QA and Production Channels*
* Add and manage third-party channels.
* Simplify compliance.
*Audit the Patch Status for {ISVPartner} HANA and Subsystems*
* Track the configuration changes and make sure all administrators have the right authority for changes.
* Slash costs of ownership.
*Automate System Management Tasks for {ISVPartner} HANA and All Other Subsystems*
* Leverage a single, web-based interface to see the status of all your servers.
* Use your resources effectively.

== Summary
SUSE CaaS Platform is an excellent environment for creating an {ISVPartner} {ISVProductName} implementation. This composable infrastructure enables you to define appropriate hardware from software descriptions. This means you can easily scale, adjust and customize your environment to fit your needs as you move from a proof-of-concept toward a production environment. SUSE CaaS Platform is an enterprise Kubernetes container platform that provides software infrastructure for not only the {ISVPartner} Data Intelligence software described in this reference, but also the data analytics applications you will build to ingest and manage your data. All of the software environments in this reference architecture are supported products and have been tested to work together on industry-standard x86-64 gear.

Join the best. Run your {ISVPartner} solutions on SUSE